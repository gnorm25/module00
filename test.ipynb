{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda ready!\n"
     ]
    }
   ],
   "source": [
    "# Linux\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "\tprint(\"Cuda ready!\")\n",
    "\tdevice = \"cuda\"\n",
    "else:\n",
    "\tprint(\"Cuda driver not installed, device set to CPU\")\n",
    "\tdevice = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [0], 'b': [0], 'c': [0], 'd': [0]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= ['a', 'b', 'c', 'd']\n",
    "tt= dict.fromkeys(test, [0])\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "friends= [\"muzi\", \"ryan\", \"frodo\", \"neo\"] \n",
    "gifts= [\"muzi frodo\", \"muzi frodo\", \"ryan muzi\", \"ryan muzi\", \"ryan muzi\", \"frodo muzi\", \"frodo ryan\", \"neo muzi\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbd_2= dict.fromkeys(friends, [0, ])\n",
    "dbd= {\"muzi\": [0], \"ryan\": [0], \"frodo\": [0], \"neo\": [0]}\n",
    "dbd_2==dbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'muzi': [0], 'ryan': [0], 'frodo': [0], 'neo': [0]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbd= dict.fromkeys(friends, [0, ])\n",
    "dbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'muzi': [0], 'ryan': [0], 'frodo': [0], 'neo': [0]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbd= {\"muzi\": [0], \"ryan\": [0], \"frodo\": [0], \"neo\": [0]}\n",
    "dbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'muzi': [-3, 'frodo', 'frodo'],\n",
       " 'ryan': [2, 'muzi', 'muzi', 'muzi'],\n",
       " 'frodo': [0, 'muzi', 'ryan'],\n",
       " 'neo': [1, 'muzi']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for x in gifts: \n",
    "    give, save = x.split()\n",
    "    dbd[give][0]+= 1 \n",
    "    dbd[save][0]-= 1 \n",
    "    dbd[give].append(save)\n",
    "dbd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(friends, gifts): \n",
    "    index= {friend: [0] for friend in friends}\n",
    "    answer= {friend: 0 for friend in friends}\n",
    "    \n",
    "    for x in gifts: \n",
    "        give, receive = x.split()\n",
    "        index[give][0]+= 1 \n",
    "        index[receive][0]-= 1 \n",
    "        index[give].append(receive)\n",
    "        \n",
    "    for x in range(len(friends)-1): \n",
    "        for y in range(x+1, len(friends)): \n",
    "            a= index[friends[x]].count(friends[y])\n",
    "            b= index[friends[y]].count(friends[x])\n",
    "            if a==b: \n",
    "                if index[friends[x]][0]>index[friends[y]][0]:\n",
    "                    answer[friends[x]]+= 1\n",
    "                elif index[friends[x]][0]<index[friends[y]][0]:\n",
    "                    answer[friends[y]]+= 1\n",
    "            elif a>b: \n",
    "                answer[friends[x]]+= 1\n",
    "            else: \n",
    "                answer[friends[y]]+= 1\n",
    "    return max(answer.values())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "friends= [\"muzi\", \"ryan\", \"frodo\", \"neo\"] \n",
    "gifts= [\"muzi frodo\", \"muzi frodo\", \"ryan muzi\", \"ryan muzi\", \"ryan muzi\", \"frodo muzi\", \"frodo ryan\", \"neo muzi\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution(friends, gifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1., 2., 3.],\n",
    "                       [4., 5., 6.],\n",
    "                       [7., 8., 9.],\n",
    "                       [10., 11., 12.]\n",
    "                      ])\n",
    "print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: [10, 4], 1: [40, 2], 5: [4, 2]}\n"
     ]
    }
   ],
   "source": [
    "N= int(input())\n",
    "npt={}\n",
    "for x in range(N):\n",
    "    a= input().split()\n",
    "    npt.update({int(a[0]): [int(a[1]), int(a[2])]})\n",
    "print(npt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "npt2= npt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "npt2= dict(sorted(npt2.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [40, 2], 2: [10, 4], 5: [4, 2]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= [1, 2]\n",
    "t= x[:0]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "torch.Size([3, 1])\n",
      "tensor([[2.],\n",
      "        [4.],\n",
      "        [6.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "\n",
    "print(x_train)\n",
    "print(x_train.shape)\n",
    "\n",
    "\n",
    "print(y_train)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros(1, requires_grad=True) \n",
    "# 가중치 W를 출력\n",
    "print(W) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= torch.zeros(1, requires_grad= True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_pred = x_train * W + b\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18.6667, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss= torch.mean((y_train-y_pred)**2)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer= optim.SGD([W, b], lr= 0.01)\n",
    "# optim.SGD(model.parameters(), lr= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1999 W: 0.187, b: 0.080 Cost: 18.666666\n",
      "Epoch  100/1999 W: 1.746, b: 0.578 Cost: 0.048171\n",
      "Epoch  200/1999 W: 1.800, b: 0.454 Cost: 0.029767\n",
      "Epoch  300/1999 W: 1.843, b: 0.357 Cost: 0.018394\n",
      "Epoch  400/1999 W: 1.876, b: 0.281 Cost: 0.011366\n",
      "Epoch  500/1999 W: 1.903, b: 0.221 Cost: 0.007024\n",
      "Epoch  600/1999 W: 1.924, b: 0.174 Cost: 0.004340\n",
      "Epoch  700/1999 W: 1.940, b: 0.136 Cost: 0.002682\n",
      "Epoch  800/1999 W: 1.953, b: 0.107 Cost: 0.001657\n",
      "Epoch  900/1999 W: 1.963, b: 0.084 Cost: 0.001024\n",
      "Epoch 1000/1999 W: 1.971, b: 0.066 Cost: 0.000633\n",
      "Epoch 1100/1999 W: 1.977, b: 0.052 Cost: 0.000391\n",
      "Epoch 1200/1999 W: 1.982, b: 0.041 Cost: 0.000242\n",
      "Epoch 1300/1999 W: 1.986, b: 0.032 Cost: 0.000149\n",
      "Epoch 1400/1999 W: 1.989, b: 0.025 Cost: 0.000092\n",
      "Epoch 1500/1999 W: 1.991, b: 0.020 Cost: 0.000057\n",
      "Epoch 1600/1999 W: 1.993, b: 0.016 Cost: 0.000035\n",
      "Epoch 1700/1999 W: 1.995, b: 0.012 Cost: 0.000022\n",
      "Epoch 1800/1999 W: 1.996, b: 0.010 Cost: 0.000013\n",
      "Epoch 1900/1999 W: 1.997, b: 0.008 Cost: 0.000008\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "# 모델 초기화\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.01)\n",
    "\n",
    "nb_epochs = 1999 # 원하는만큼 경사 하강법을 반복\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train * W + b\n",
    "\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7a5bb5d3d0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 선언 및 초기화. 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
    "model = nn.Linear(3,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 31667.597656\n",
      "Epoch  100/2000 Cost: 0.225993\n",
      "Epoch  200/2000 Cost: 0.223911\n",
      "Epoch  300/2000 Cost: 0.221941\n",
      "Epoch  400/2000 Cost: 0.220059\n",
      "Epoch  500/2000 Cost: 0.218271\n",
      "Epoch  600/2000 Cost: 0.216575\n",
      "Epoch  700/2000 Cost: 0.214950\n",
      "Epoch  800/2000 Cost: 0.213413\n",
      "Epoch  900/2000 Cost: 0.211952\n",
      "Epoch 1000/2000 Cost: 0.210560\n",
      "Epoch 1100/2000 Cost: 0.209232\n",
      "Epoch 1200/2000 Cost: 0.207967\n",
      "Epoch 1300/2000 Cost: 0.206761\n",
      "Epoch 1400/2000 Cost: 0.205619\n",
      "Epoch 1500/2000 Cost: 0.204522\n",
      "Epoch 1600/2000 Cost: 0.203484\n",
      "Epoch 1700/2000 Cost: 0.202485\n",
      "Epoch 1800/2000 Cost: 0.201542\n",
      "Epoch 1900/2000 Cost: 0.200635\n",
      "Epoch 2000/2000 Cost: 0.199769\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
    "\n",
    "    # cost로 H(x) 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward()\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[151.2305]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2802], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module): # torch.nn.Module을 상속받는 파이썬 클래스\n",
    "    def __init__(self): #\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(3, 3) # 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
    "        self.linear2= nn.Linear(3, 1)\n",
    "        self.relu= nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.linear1(x) \n",
    "        x= self.relu(x) \n",
    "        x= self.linear2(x) \n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.5644,  0.3579,  0.1613],\n",
       "         [ 0.5476,  0.3811, -0.5260],\n",
       "         [-0.5489, -0.2785,  0.5070]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0962,  0.2471, -0.2683], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.5665, -0.2443,  0.4330]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0068], requires_grad=True)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 32594.255859\n",
      "Epoch  100/2000 Cost: 30203.275391\n",
      "Epoch  200/2000 Cost: 29591.871094\n",
      "Epoch  300/2000 Cost: 29558.113281\n",
      "Epoch  400/2000 Cost: 29524.261719\n",
      "Epoch  500/2000 Cost: 29490.375000\n",
      "Epoch  600/2000 Cost: 29456.474609\n",
      "Epoch  700/2000 Cost: 29422.574219\n",
      "Epoch  800/2000 Cost: 29388.681641\n",
      "Epoch  900/2000 Cost: 29354.800781\n",
      "Epoch 1000/2000 Cost: 29320.933594\n",
      "Epoch 1100/2000 Cost: 29287.083984\n",
      "Epoch 1200/2000 Cost: 29253.250000\n",
      "Epoch 1300/2000 Cost: 29219.443359\n",
      "Epoch 1400/2000 Cost: 29185.650391\n",
      "Epoch 1500/2000 Cost: 29151.880859\n",
      "Epoch 1600/2000 Cost: 29118.134766\n",
      "Epoch 1700/2000 Cost: 29084.406250\n",
      "Epoch 1800/2000 Cost: 29050.699219\n",
      "Epoch 1900/2000 Cost: 29017.015625\n",
      "Epoch 2000/2000 Cost: 28983.355469\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
    "\n",
    "    # cost로 H(x) 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward()\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  90], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader= DataLoader(dataset, batch_size= 2, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[73., 80., 75.],\n",
      "        [89., 91., 90.]]), tensor([[152.],\n",
      "        [180.]])]\n",
      "1 [tensor([[ 93.,  88.,  93.],\n",
      "        [ 96.,  98., 100.]]), tensor([[185.],\n",
      "        [196.]])]\n",
      "2 [tensor([[73., 66., 70.]]), tensor([[142.]])]\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataLoader): \n",
    "    print(i, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionModel(\n",
      "  (linear1): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (linear2): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LinearRegressionModel(nn.Module): # torch.nn.Module을 상속받는 파이썬 클래스\n",
    "    def __init__(self): #\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(3, 3)\n",
    "        self.linear2= nn.Linear(3, 1)\n",
    "        self.relu= nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.linear1(x) \n",
    "        x= self.relu(x) \n",
    "        x= self.linear2(x) \n",
    "\n",
    "        return x \n",
    "model= LinearRegressionModel()\n",
    "#.todevice()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Batch 0/3 Cost: 28706.398438\n",
      "Epoch    0/1000 Batch 1/3 Cost: 29275.015625\n",
      "Epoch    0/1000 Batch 2/3 Cost: 32323.255859\n",
      "Epoch   50/1000 Batch 0/3 Cost: 21846.726562\n",
      "Epoch   50/1000 Batch 1/3 Cost: 21202.837891\n",
      "Epoch   50/1000 Batch 2/3 Cost: 24345.175781\n",
      "Epoch  100/1000 Batch 0/3 Cost: 16312.181641\n",
      "Epoch  100/1000 Batch 1/3 Cost: 15699.826172\n",
      "Epoch  100/1000 Batch 2/3 Cost: 18382.910156\n",
      "Epoch  150/1000 Batch 0/3 Cost: 13074.811523\n",
      "Epoch  150/1000 Batch 1/3 Cost: 14549.783203\n",
      "Epoch  150/1000 Batch 2/3 Cost: 6396.157715\n",
      "Epoch  200/1000 Batch 0/3 Cost: 9199.960938\n",
      "Epoch  200/1000 Batch 1/3 Cost: 11125.064453\n",
      "Epoch  200/1000 Batch 2/3 Cost: 5601.076660\n",
      "Epoch  250/1000 Batch 0/3 Cost: 3268.133545\n",
      "Epoch  250/1000 Batch 1/3 Cost: 10108.716797\n",
      "Epoch  250/1000 Batch 2/3 Cost: 8062.455078\n",
      "Epoch  300/1000 Batch 0/3 Cost: 2102.921875\n",
      "Epoch  300/1000 Batch 1/3 Cost: 7958.129883\n",
      "Epoch  300/1000 Batch 2/3 Cost: 6154.340820\n",
      "Epoch  350/1000 Batch 0/3 Cost: 3210.430176\n",
      "Epoch  350/1000 Batch 1/3 Cost: 5973.099609\n",
      "Epoch  350/1000 Batch 2/3 Cost: 1664.133545\n",
      "Epoch  400/1000 Batch 0/3 Cost: 3462.875000\n",
      "Epoch  400/1000 Batch 1/3 Cost: 2085.283203\n",
      "Epoch  400/1000 Batch 2/3 Cost: 4288.018555\n",
      "Epoch  450/1000 Batch 0/3 Cost: 1823.850464\n",
      "Epoch  450/1000 Batch 1/3 Cost: 3829.413818\n",
      "Epoch  450/1000 Batch 2/3 Cost: 640.171204\n",
      "Epoch  500/1000 Batch 0/3 Cost: 3110.399658\n",
      "Epoch  500/1000 Batch 1/3 Cost: 224.911530\n",
      "Epoch  500/1000 Batch 2/3 Cost: 2717.001221\n",
      "Epoch  550/1000 Batch 0/3 Cost: 883.249756\n",
      "Epoch  550/1000 Batch 1/3 Cost: 2768.671143\n",
      "Epoch  550/1000 Batch 2/3 Cost: 189.822342\n",
      "Epoch  600/1000 Batch 0/3 Cost: 1588.496826\n",
      "Epoch  600/1000 Batch 1/3 Cost: 1459.793091\n",
      "Epoch  600/1000 Batch 2/3 Cost: 0.629719\n",
      "Epoch  650/1000 Batch 0/3 Cost: 748.678345\n",
      "Epoch  650/1000 Batch 1/3 Cost: 1778.562256\n",
      "Epoch  650/1000 Batch 2/3 Cost: 28.792454\n",
      "Epoch  700/1000 Batch 0/3 Cost: 485.004761\n",
      "Epoch  700/1000 Batch 1/3 Cost: 1680.608398\n",
      "Epoch  700/1000 Batch 2/3 Cost: 4.342991\n",
      "Epoch  750/1000 Batch 0/3 Cost: 891.401489\n",
      "Epoch  750/1000 Batch 1/3 Cost: 934.362305\n",
      "Epoch  750/1000 Batch 2/3 Cost: 116.628860\n",
      "Epoch  800/1000 Batch 0/3 Cost: 309.317444\n",
      "Epoch  800/1000 Batch 1/3 Cost: 1264.677124\n",
      "Epoch  800/1000 Batch 2/3 Cost: 179.579468\n",
      "Epoch  850/1000 Batch 0/3 Cost: 133.794617\n",
      "Epoch  850/1000 Batch 1/3 Cost: 999.134644\n",
      "Epoch  850/1000 Batch 2/3 Cost: 758.969055\n",
      "Epoch  900/1000 Batch 0/3 Cost: 178.317047\n",
      "Epoch  900/1000 Batch 1/3 Cost: 883.691162\n",
      "Epoch  900/1000 Batch 2/3 Cost: 655.443115\n",
      "Epoch  950/1000 Batch 0/3 Cost: 792.613159\n",
      "Epoch  950/1000 Batch 1/3 Cost: 467.116608\n",
      "Epoch  950/1000 Batch 2/3 Cost: 81.968849\n",
      "Epoch 1000/1000 Batch 0/3 Cost: 463.188721\n",
      "Epoch 1000/1000 Batch 1/3 Cost: 615.513000\n",
      "Epoch 1000/1000 Batch 2/3 Cost: 304.727173\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=5e-4) \n",
    "\n",
    "epochs= 1000 \n",
    "for epoch in range(epochs+1): \n",
    "    for idx, batch in enumerate(dataLoader): \n",
    "        x, y_true= batch \n",
    "        y_pred= model(x) \n",
    "\n",
    "        loss= F.mse_loss(y_pred, y_true)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        if epoch%50== 0: \n",
    "            print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "        epoch, epochs, idx, len(dataLoader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 상속\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self):\n",
    "    self.x_data = [[73, 80, 75], \n",
    "                   [93, 88, 93],\n",
    "                   [89, 91, 90],\n",
    "                   [96, 98, 100],\n",
    "                   [73, 66, 70]]\n",
    "    self.y_data = [[152], [185], [180], [196], [142]]\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "  def __getitem__(self, idx): \n",
    "    x = torch.FloatTensor(self.x_data[idx])\n",
    "    y = torch.FloatTensor(self.y_data[idx])\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[73., 66., 70.],\n",
      "        [93., 88., 93.]]), tensor([[142.],\n",
      "        [185.]])]\n",
      "1 [tensor([[ 89.,  91.,  90.],\n",
      "        [ 96.,  98., 100.]]), tensor([[180.],\n",
      "        [196.]])]\n",
      "2 [tensor([[73., 80., 75.]]), tensor([[152.]])]\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataloader): \n",
    "    print(i, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 307.521484\n",
      "Epoch    0/20 Batch 2/3 Cost: 770.384033\n",
      "Epoch    0/20 Batch 3/3 Cost: 303.686584\n",
      "Epoch    1/20 Batch 1/3 Cost: 709.626465\n",
      "Epoch    1/20 Batch 2/3 Cost: 306.868805\n",
      "Epoch    1/20 Batch 3/3 Cost: 425.271667\n",
      "Epoch    2/20 Batch 1/3 Cost: 463.057312\n",
      "Epoch    2/20 Batch 2/3 Cost: 613.905212\n",
      "Epoch    2/20 Batch 3/3 Cost: 302.279938\n",
      "Epoch    3/20 Batch 1/3 Cost: 707.577026\n",
      "Epoch    3/20 Batch 2/3 Cost: 270.127716\n",
      "Epoch    3/20 Batch 3/3 Cost: 499.929382\n",
      "Epoch    4/20 Batch 1/3 Cost: 705.950684\n",
      "Epoch    4/20 Batch 2/3 Cost: 306.022552\n",
      "Epoch    4/20 Batch 3/3 Cost: 428.258057\n",
      "Epoch    5/20 Batch 1/3 Cost: 306.195709\n",
      "Epoch    5/20 Batch 2/3 Cost: 768.948303\n",
      "Epoch    5/20 Batch 3/3 Cost: 299.779724\n",
      "Epoch    6/20 Batch 1/3 Cost: 703.929565\n",
      "Epoch    6/20 Batch 2/3 Cost: 462.845276\n",
      "Epoch    6/20 Batch 3/3 Cost: 115.116760\n",
      "Epoch    7/20 Batch 1/3 Cost: 305.675507\n",
      "Epoch    7/20 Batch 2/3 Cost: 702.860840\n",
      "Epoch    7/20 Batch 3/3 Cost: 430.544769\n",
      "Epoch    8/20 Batch 1/3 Cost: 272.395813\n",
      "Epoch    8/20 Batch 2/3 Cost: 703.427856\n",
      "Epoch    8/20 Batch 3/3 Cost: 495.580048\n",
      "Epoch    9/20 Batch 1/3 Cost: 767.929688\n",
      "Epoch    9/20 Batch 2/3 Cost: 206.453094\n",
      "Epoch    9/20 Batch 3/3 Cost: 494.167969\n",
      "Epoch   10/20 Batch 1/3 Cost: 767.535034\n",
      "Epoch   10/20 Batch 2/3 Cost: 304.756500\n",
      "Epoch   10/20 Batch 3/3 Cost: 295.693451\n",
      "Epoch   11/20 Batch 1/3 Cost: 393.495056\n",
      "Epoch   11/20 Batch 2/3 Cost: 766.931519\n",
      "Epoch   11/20 Batch 3/3 Cost: 117.664032\n",
      "Epoch   12/20 Batch 1/3 Cost: 697.203979\n",
      "Epoch   12/20 Batch 2/3 Cost: 304.041351\n",
      "Epoch   12/20 Batch 3/3 Cost: 435.442688\n",
      "Epoch   13/20 Batch 1/3 Cost: 205.945251\n",
      "Epoch   13/20 Batch 2/3 Cost: 766.828003\n",
      "Epoch   13/20 Batch 3/3 Cost: 490.370117\n",
      "Epoch   14/20 Batch 1/3 Cost: 462.637085\n",
      "Epoch   14/20 Batch 2/3 Cost: 695.091553\n",
      "Epoch   14/20 Batch 3/3 Cost: 118.888054\n",
      "Epoch   15/20 Batch 1/3 Cost: 462.618835\n",
      "Epoch   15/20 Batch 2/3 Cost: 205.651703\n",
      "Epoch   15/20 Batch 3/3 Cost: 1095.848755\n",
      "Epoch   16/20 Batch 1/3 Cost: 278.748627\n",
      "Epoch   16/20 Batch 2/3 Cost: 791.261719\n",
      "Epoch   16/20 Batch 3/3 Cost: 291.004456\n",
      "Epoch   17/20 Batch 1/3 Cost: 364.834564\n",
      "Epoch   17/20 Batch 2/3 Cost: 605.964294\n",
      "Epoch   17/20 Batch 3/3 Cost: 485.439850\n",
      "Epoch   18/20 Batch 1/3 Cost: 605.234802\n",
      "Epoch   18/20 Batch 2/3 Cost: 462.499634\n",
      "Epoch   18/20 Batch 3/3 Cost: 288.970947\n",
      "Epoch   19/20 Batch 1/3 Cost: 204.893188\n",
      "Epoch   19/20 Batch 2/3 Cost: 764.750488\n",
      "Epoch   19/20 Batch 3/3 Cost: 482.821106\n",
      "Epoch   20/20 Batch 1/3 Cost: 603.929138\n",
      "Epoch   20/20 Batch 2/3 Cost: 462.443848\n",
      "Epoch   20/20 Batch 3/3 Cost: 286.957489\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "  for batch_idx, samples in enumerate(dataloader):\n",
    "    # print(batch_idx)\n",
    "    # print(samples)\n",
    "    x_train, y_train = samples\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 계산\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
    "        cost.item()\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
